import os
os.environ["ANONYMIZED_TELEMETRY"] = "False"  # Para desactivar telemetr√≠a en ChromaDB
os.environ["LANGCHAIN_TRACING"] = "False"  # Para desactivar telemetr√≠a en LangChain
os.environ["OTEL_SDK_DISABLED"] = "true"  # Para desactivar telemetr√≠a en OpenTelemetry
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from embeddings.extraer_preguntas import obtener_preguntas_y_metadatos
from utils_for_all.utilidades_logs import setup_logger

# se activa telemetr√≠a autom√°ticamente en LangChain/CromaDB porque utilizan opentelemetry y posthog internamente 
# para recolectar m√©tricas de uso.
# VS Code tambi√©n intenta enviar telemetr√≠a, generando un conflicto con los argumentos de las funciones. 
# Desactivar telemetr√≠a en Chroma/LangChain

def crear_base_vectorial():
    logger_embeddings = setup_logger("logger_embeddings", "logs_generacion_embeddings.txt")
    preguntas, metadatos = obtener_preguntas_y_metadatos()
    if not preguntas:
        logger_embeddings.debug("‚ö†Ô∏è No se generaron embeddings por falta de preguntas.")
        return None
    modelo = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vectordb = Chroma.from_texts(
        texts=preguntas,
        embedding=modelo,
        metadatas=metadatos,
        persist_directory="./chroma",
        anonymized_telemetry=False  # üëà Desactiva telemetr√≠a aqu√≠
    )
    logger_embeddings.debug("‚úÖ Base vectorial creada con √©xito.")
    return vectordb

def get_base_de_datos_vectorial(): 
    # Carga de modelo y base vectorial persistente
    modelo = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    return Chroma(persist_directory="./chroma", embedding_function=modelo)